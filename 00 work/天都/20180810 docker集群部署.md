[TOC]

> docker version 18.05.0-ce

# 镜像管理

## 使用域名

`/etc/hosts`  或 `C:\Windows\System32\drivers\etc\hosts`

```
10.48.78.172 dev.app
```

## 镜像仓库

暂不考虑安全与集群

- windows鼠标右键docker，设置daemon

- linux：` /etc/docker/daemon.json` 

```json
{
    "registry-mirrors": ["https://registry.docker-cn.com"],
    "insecure-registries" : ["http://dev.app:5000","http://test.app:5000","http://prod.app:5000"]
}
```

```bash
# 启动私有镜像仓库
docker run -d \
  -p 5000:5000 \
  --restart always \
  --name registry \
  registry
# 标记镜像为私有仓库镜像
docker tag tdapp/tdportal dev.app:5000/tdapp/tdportal
docker push dev.app:5000/tdapp/tdportal
docker pull dev.app:5000/tdapp/tdportal
 # 查看仓库中的镜像列表
curl http://dev.app:5000/v2/_catalog
curl http://dev.app:5000/v2/{image}/tags/list
```

## TODO镜像仓库安全



## 镜像版本

利用`gitlab`的`CI/CD`，手动`Run Pipeline`

- 发布版本前，需要创建版本分支
- 去到gitlab对应项目的`CI/CD`
- 创建`Run Pipeline`
- 选择需要发布的分支
- 填入Variables：RELEASE=true
- pipeline执行完后，手动触发版本发布job

```yaml
job_deploy_prod:
  stage: deploy_prod
  when: manual
  only:
    refs:
      - branches@g3/TianduApp
    variables:
      - $RELEASE == "true"
  script:
    - cat README.md
    - mvn -Dmaven.test.skip=true package
    - docker build -t prod.app:5000/tdapp/tianduapp:$CI_COMMIT_REF_NAME .
    - docker tag prod.app:5000/tdapp/tianduapp:$CI_COMMIT_REF_NAME prod.app:5000/tdapp/tianduapp:latest
    - docker push prod.app:5000/tdapp/tianduapp:$CI_COMMIT_REF_NAME
    - docker push prod.app:5000/tdapp/tianduapp:latest
  environment:
    name: production
    url: http://prod.app:5000/v2/tdapp/tianduapp/tags/list
```

# 集群操作

>  https://docs.docker.com
>
> https://docs.docker.com/engine/swarm/swarm-tutorial/ 

## 加入与离开集群

```bash
# 创建集群，创建后当前机器即为manage节点，多个网卡时，可能需要指定IP
docker swarm init [ --advertise-addr 当前机器IP]
# 在manage节点查看加入集群的命令，注意时间同步
docker swarm join-token [worker|manager]
# 主动离开集群
docker swarm leave [--force]
```

## 节点管理

```bash
# 查看节点列表
docker node ls
# 移除节点
docker node rm [--force] NODE [NODE...]
# 移除状态为DOWN的节点
docker node ls | grep Down | awk '{print $1}' | xargs -n 1 -I ID docker node rm -f ID
# 查看某个节点运行的容器，默认查当前机器节点
docker node ps [--filter name=redis] [NODE...]
# 查看节点信息
docker node inspect --pretty self|NODE
# 节点阶级，不再是manager
docker node demote NODE
# 节点升级为manager
docker node promote NODE
```

## 添加节点的处理

新节点添加镜像仓库



为节点设置label，可以通过 --constants部署指定label的节点

## 删除节点前的准备

如何移除指定节点的实例

断路，不接受新请求，正在处理的请求继续

## 集群中部署服务栈

一堆不同的服务一起组成服务栈，若要移除某个服务所有实例：`docker service scale -d tdportal=0`

```bash
# 部署或更新服务栈
docker stack deploy [OPTIONS] STACK
# 示例：通过compose file部署服务栈
docker stack deploy --compose-file docker-compose-tdapp.yml tdapp
# 查看部署的应用，及实例数量
docker stack ls
# 查看某个服务栈中所有执行过的实例，需在manager节点使用
docker stack ps [-f name=tdapp_tdportal -f node=node01] STACK
# 查看服务栈中的服务列表，及各服务实例数量
docker stack services tdapp
# 删除服务栈
docker stack rm tdapp
```

## 集群中服务管理

`docker service`可以管理`docker stack`部署的服务

```bash
# 创建服务，docker-compose文件中各配置项与此命令中的选项对应
docker service create [OPTIONS] IMAGE
# 示例
docker service create -d \
  --replicas 2 \
  --network name=tdapp_tdapp,alias=tdportal \
  -p 8080:8080 \
  --constraint 'node.role == manager' \
  -e SPRING_PROFILES_ACTIVE=dev \
  -e SPRING_CLOUD_CONFIG_ENABLED=true \
  -e SPRING_CLOUD_CONFIG_DISCOVERY_ENABLED=true \
  -e EUREKA_CLIENT_ENABLED=true \
  -e EUREKA_CLIENT_SERVICEURL_DEFAULTZONE=http://10.48.78.172:7080/eureka \
  --name tdportal \
  tdapp/tdportal
# 查看服务列表
docker service ls
# 查看指定服务信息
docker service inspect --pretty tdportal
# 查看指定服务实例信息
docker service ps tdportal
# 删除指定服务
docker service rm tdportal
# 将服务规模化，即控制服务实例数量，可增加，也可减少
docker service scale -d tdportal=2
docker service scale tdportal=2
# 更新服务，参数与create差不多
docker service update [OPTIONS] SERVICE
# 示例
docker service update --constraint-rm 'node.role == manager' tdportal
docker service update --constraint-add 'node.role == worker' tdportal
# 恢复最近一次update的修改
docker service rollback SERVICE
# 查看服务日志，显示所有实例的日志，当logging driver为json-file或journald时有效
docker service logs 服务ID或服务名称
# 查看每个实例最后100行日志 
docker service logs --tail 100 tdportal
docker service logs --since 2018-08-10Z --tail 100 tdportal
docker service logs -f --since 2018-08-10T06:30Z --tail 100 tdportal
```

# 日志管理ELK

>  https://docs.docker.com/config/containers/logging/configure/
>
> docker swarm集群日志管理ELK实战 https://blog.csdn.net/dkfajsldfsdfsd/article/details/79987753

## 修改内存地址映射mmp的系统限制

elasticsearch是一个文档数据库，以mmap的方式管理索引。mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式，向操作内存一样读写文件。mmap以页为单位实现映射，操作系统对页的的数量有限制，默认的值太小，elasticsearch要求的最小值是262144，小于此值elasticsearch无法启动。分别在三个node上执行以下命令，临时扩大这种限制：

```bash
sysctl -w vm.max_map_count=262144
```

这种方法在系统重启后就会失效，永久生效的方法是修改文件`/etc/sysctl.conf`中的`vm.max_map_count`值并重启系统。

`echo vm.max_map_count=262144 >> /etc/sysctl.conf `

## stack yaml

`docker-stack-elk.yml`

```yaml
version: '3'
 
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.3.2
    environment:
      ES_JAVA_OPTS: '-Xms256m -Xmx256m'
      xpack.security.enabled: 'false'
      xpack.monitoring.enabled: 'false'
      xpack.graph.enabled: 'false'
      xpack.watcher.enabled: 'false'
    volumes:
      - esdata:/usr/share/elasticsearch/data
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
 
  logstash:
    image: docker.elastic.co/logstash/logstash:5.3.2
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
 
  logspout:
    image: bekt/logspout-logstash
    environment:
      ROUTE_URIS: 'logstash://logstash:5001'
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - logstash
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
        delay: 30s
 
  kibana:
    image: docker.elastic.co/kibana/kibana:5.3.2
    ports:
      - '5601:5601'
    depends_on:
      - elasticsearch
    environment:
      ELASTICSEARCH_URL: 'http://elasticsearch:9200'
      XPACK_SECURITY_ENABLED: 'false'
      XPACK_MONITORING_ENABLED: 'false'
    deploy:
      replicas: 1
 
volumes:
  esdata:
    driver: local
```

## 日志查询

http://10.48.78.172:5601/

## TODO

elk日志保存在哪，会不会积累过大

原docker容器日志日志是否还在

# 服务监控



# 链路跟踪

